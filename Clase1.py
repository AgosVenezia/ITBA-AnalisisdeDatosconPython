# -*- coding: utf-8 -*-
"""Copia de Clase_1_Analisis_de_Datos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lyJlvlJoAsnxGyFlS5pJxtOUZD2eqimk

# ¡Bienvenidos al Curso de Análisis de Datos en Python!
!Hola! Somos estudiantes voluntarios en la rama estudiantil IEEE del Instituto Tecnológico de Buenos Aires y organizamos este curso de Análisis de Datos en Python gratuito y abierto al público general.

\
<img height="150" src="https://raw.githubusercontent.com/IEEESBITBA/Curso-python/master/_assets/logo-oficial.png">

\
\
Este curso forma parte de una serie de cursos que ofrecemos. Tiene como objetivo principal que los participantes aprendan lo suficiente para:
* Automatizar tareas comunes.
* Manipular archivos y hojas de datos de manera eficiente.
* Representar información gráficamente de manera sencilla.

Todas estas tareas pueden ser realizadas usando programación sin necesidad de convertirse en un experto del tema.

El contenido de este curso introductorio está orientado hacia aquellos que tienen conocimientos básicos sobre programación en Python (tales como tipos de datos, funciones y estructuras de datos). Se verán conceptos y temas fundamentales acerca de librerías, lectura de archivos y análisis y representación de datos, poniendo en práctica lo aprendido mediante desafíos interactivos y ejercicios prácticos.


\
El curso consiste en 2 clases, los temas y conceptos a cubrir son los siguientes:


**Clase 1 :**
*     Introducción a librerías.
*     Lectura y escritura de archivos formato Excel y CSV.
*     Manipulación de datos con Pandas.

**Clase 2 :**
*     Introducción a matplotlib.
*     Visualización de datos.
*     Personalización de los gráficos.

\

En nuestro esmero por proveer un curso adaptable y flexible a la disponibilidad de la mayor cantidad de personas, se optó por una modalidad "semi-sincrónica", en la cual los participantes lleven un ritmo similar, pero que dentro de cada semana puedan dedicar su tiempo de la forma que prefieran.

Las clases serán publicadas semanalmente y estarán compuestas de videos y textos complementarios como también desafíos prácticos para pensar y resolver. Entre clase y clase tendrán una semana para leer, ver los videos, practicar, y conversar con sus compañeros. El fin de semana entre clase y clase habrá un Livestream donde podrán sacarse las dudas que tengan.

¡No dejen pasar la oportunidad de resolver los desafíos! Son una gran oportunidad para comprender realmente lo que acaban de ver y practicar, algunos son fáciles y otros difíciles así que no se desanimen si tarda en llegar la idea para resolverlos, ya que ese es el punto, ¡desafiarse!

La ejercitación integradora incluye muchos más ejercicios al final de la clase. En este caso no es crucial terminarlos todos, pero sí les recomendamos hacer los que puedan de acuerdo al tiempo del que dispongan, ya que creemos que la puesta en práctica de los conocimientos es la mejor manera de aprender.

\
**Certificado:** Para obtener un certificado de finalización del curso se debe completar exitosamente el **cuestionario de fin de curso**:
* Se les habilitará durante la última semana de clase: del 3/10 al 9/10 (incluídos).
* Consta de preguntas sobre los temas que verán en el curso.
* Tendrán múltiples intentos para entregarlo. 

Podrán encontrar los cuestionarios en nuestra [página web](https://ieeeitba.org.ar/data-analysis), y se habilitará uno por día durante la semana de evaluación. Tienen una chance por día para aprobar el cuestionario, y se aprueba con 9/10 respuestas correctas. Estas evaluaciones no tienen un tiempo fijo para resolverlas, ¡así que tómense el tiempo para pensar cada pregunta!

\
**Comunicación:** Si no lo hicieron ya deben unirse a nuestro servidor de Discord para recibir todos los anuncios del curso. Pueden hacerlo usando el [siguiente link](https://discord.gg/BndgqWGwGj). Allí pueden conversar con otros participantes del curso, y hacer todas las consultas que deseen, por más elementales que puedan ser. Están invitados a participar y ayudar a sus compañeros, además los distintos ayudantes del curso intentaremos ayudarlos con sus consultas, y las que no hayan podido ser respondidas durante la semana se podrán consultar en los Livestreams.

\

**Livestream:** Las transmisiones en vivo serán los días sábados de 18 a 19 hs (UCT-3), allí se responderan las dudas y problemáticas más usuales o concurridas. Estos quedarán grabados en caso de que no hayan podido verlo en vivo o quieran volver a revisarlo. El Livestream aparecerá disponible los días y horarios correspondientes en [nuestro canal de Youtube](https://www.youtube.com/channel/UCpWHvOSiPtDIwIw8Tb_9g6A).

\

**Nota 1:** Para poder guardar los ejercicios que resuelvan les recomendamos guardar una copia del documento en su Google Drive. La próxima vez que quieran entrar a la clase y mantener su progreso pueden acceder desde su carpeta de Drive, en lugar de usar el link original.


<img height="300" src="https://raw.githubusercontent.com/IEEESBITBA/Curso-python/master/_assets/guardar_copia_en_drive.png">

\

**Nota 2:** Si alguno de los videos no les aparece por defecto, deberán ejecutar las celdas de código en la que se encuentra ese video y luego reproducirlo. Para ejecutar una celda, tienen que clickear sobre el botón superior izquierdo del bloque en que se encuentra el código.
Cada video tratará los temas explicados en la clase. Asimismo estos se complementan con la información escrita del curso.

\
¡Esperamos que les sirva!

El material es de libre distribución bajo la licencia [Creative Commons](https://creativecommons.org) CC-BY-NC-SA.

# Introducción al Análisis de Datos

Ya sea mediante formularios web, datos analíticos de redes sociales, instrumentos científicos de medición, registros de ventas en un comercio, o de muchas otras formas, cada vez más las personas tienen crean o tienen acceso a grandes volúmenes de datos.

Sin embargo, rara vez alcanza con la recopilación de datos, estos deben ser procesados y analizados para poder extraer la información relevante y obtener conclusiones a partir de ellos. Por otro lado, estos resultados deben poder ser visualizados de forma que puedan ser interpretados tanto por quienes realizan el análisis como por personas que necesitan esta información.

Podemos entonces empezar a discernir algunos de los pasos que formarán parte del proceso de análisis de datos:

- Recopilación de datos.
- Acondicionamiento / Limpieza.
- Análisis / Procesamiento.
- Visualización de resultados.

En este curso vamos a ver una introducción a los últimos 3 puntos, mientras que la tarea de recopilación de datos será específica a los casos particulares, dada la enorme cantidad de posibles métodos de recopilación de datos.

Para lograr abarcar a la mayor cantidad de aplicaciones, en este curso nos focalizamos en la obtención de datos mediante archivos de **hojas de cálculo** (como Excel y CSV). Otros posibles métodos podrían incluír archivos JSON, HDF o bases de datos (como por ejemplo SQL). Además, una vez que aprenden a utilizar una librería para esta tarea, luego pueden empezar a utilizar todo tipo de librerías para manejar los archivos que necesiten.

<img src="https://icons-for-free.com/iconfiles/png/512/document+file+page+paper+programming+icon-1320165844326114116.png" width=300>

Esta clase resulta ser para muchos estudiantes más difícil que otras. Les recomendamos tener paciencia con los ejercicios y animarse a probar sus ideas, aunque no funcionen. Si un problema es difícil, sugerimos probar de simplificar el problema o de resolver sólo una parte del total, antes de seguir intentando. Como siempre, los desafíos no se resuelven siendo un experto, sino con **perseverancia**, **colaboración con compañeros** y **prueba y error**.

# Librerías
"""

# Link a Youtube: https://youtu.be/6wCBL7AifsU
# Tema: Librerías: concepto, instalación, importación y ejemplos.

# Dar click en el botón de play de esta celda si el video no se visualiza debajo 

from IPython.display import YouTubeVideo
YouTubeVideo('6wCBL7AifsU', width=800, height=450)

"""# Archivos .xlsx y .csv



[Pandas](https://pandas.pydata.org) es una librería muy popular en los últimos tiempos. Nos permite, entre otras cosas, sistematizar con unas pocas funciones la conversión de un archivo de información en los tipos de datos que Python maneja. En esta clase la utilizaremos para poder leer archivos con información en filas y columnas, tales como los formatos **excel** o **csv**.

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1200px-Pandas_logo.svg.png" width=600px>

## Lectura de archivos .xlsx .csv
"""

# Link a Youtube: https://youtu.be/Eq9w4uT3rYs
# Tema: Manejo de Archivos con pandas. 

# Dar click en el botón de play de esta celda si el video no se visualiza debajo

from IPython.display import YouTubeVideo
YouTubeVideo('Eq9w4uT3rYs', width=800, height=450)

"""A continuación mostraremos un ejemplo donde se accede a la información de un archivo utilizando *pandas*. El archivo que leeremos se llama **Datos.xlsx**, normalmente desde nuestra computadora podremos acceder a los archivos locales mediante su ubicación en el disco. Colab requiere cargar los archivos a su entorno antes de poder usarlos, lo cual se puede realizar mediante el siguiente comando que descarga un archivo de internet:"""

# Comando wget. Solo para maquinas Linux. ¡Colab usa Linux!
! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Datos.xlsx"

# Si no estamos en un entorno linux podemos definir nuestra propia wget
# Esta función nos ayuda a descargar archivos desde la web y no es necesaria para archivos locales
# No es necesario entender cómo funciona, se las mostramos sólo por si alguno llega a necesitarla

# Importamos la libreria requests
import requests

def wget(url):
    r = requests.get(url, allow_redirects=True)
    with open(url[url.rfind('/') + 1::], 'wb') as f:
        f.write(r.content)

wget("https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Datos.xlsx")

"""La función que utilizaremos para cargar los datos del archivo se llama [read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html). Esta función recibe como parámetro el nombre del archivo deseado. También existe la función [read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) y tiene un funcionamiento muy similar."""

import pandas as pd

archivo = pd.read_excel("Datos.xlsx") 
# La variable archivo es de un tipo de dato especial de pandas llamado 'DataFrame'
print(archivo)

"""En el ejemplo, la variable `archivo` no es de un tipo estándar de Python, sino que la librería Pandas define su propio tipo de variables. Este tipo es llamado **DataFrame** y como cualquier otro tipo, tiene sus propios métodos y características los cuales se pueden ver en la [documentación de Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).

Una forma de utilizar la información que almacenamos en la variable de tipo *DataFrame*, es convertirla en un tipo conocido. Para esto podemos convertirla a un diccionario usando el método [to_dict()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_dict.html). Esta función recibe como parámetro el tipo de diccionario deseado, dependiendo de qué forma es preferible para organizar la información.

Los diseñadores de pandas les pusieron los siguientes nombres a distintos tipos de diccionarios:
*dict*, *list*, *series*, *split*, *records*, *index*

Vamos a ver algunos de estos tipos de diccionarios que son útiles:


"""

import pandas as pd

archivo = pd.read_excel("Datos.xlsx") 
data = archivo.to_dict("list") 
# "list" significa que vamos a almacenar a cada columna como una lista con su contenido

print(data)
print(data['Nombre'])     # Accedemos a los datos de una columna
print(data['Nombre'][2])  # Accedemos al índice 2 de la columna 'Nombres'

"""El parámetro "list" sirve para crear un diccionario donde en cada elemento la *clave* es el nombre de la columna y el *contenido* es una lista con los items de la columna correspondiente.

Cambiando el parámetro "list" por "records" de la función **to_dict()** podemos obtener una lista. Cada elemento de la lista es un diccionario. Cada uno de los diccionarios en la lista corresponde a una fila de la hoja de datos, en donde para cada elemento la *clave* es el nombre de la columna mientras que el *contenido* es 1 solo dato, el dato de la columna y fila correspondiente.
"""

import pandas as pd

archivo = pd.read_excel("Datos.xlsx") 

data = archivo.to_dict("records") 
# "records" significa que vamos a obtener el contenido separado por cada fila

print(data)
print(data[2])            # Accedemos a los datos de una fila
print(data[2]['Nombre'])  # Accedemos a la columna 'Nombres' de la fila con índice 2

"""A veces es necesario "indexar" el archivo por alguna columna en particular, en estos casos 
podemos agregar un parámetro *index_col* con el nombre de la columna que servirá de índice para los datos.
Es importante notar que la columna seleccionada no puede tener valores repetidos, ya que los datos de esta columna serán las claves del diccionario generado.
"""

import pandas as pd

# Indicamos que la columna de indexación será apellido.
archivo = pd.read_excel("Datos.xlsx", index_col ="Apellido") 
print(archivo)

data = archivo.to_dict("index") 
# "index" significa que vamos a obtener el contenido como diccionarios 
# donde la clave es algun campo de cada fila, en este caso la clave de los 
# diccionarios será la clave "Apellido"

# convertimos el tipo de dato de pandas a un dict de python

print(data)
print(data['Martinez'])           # Accedemos a los datos de una fila (usando el dato de índice apropiado)
print(data['Martinez']['Legajo']) # Accedemos a la columna 'Legajo' de la fila con índice 'Martinez'

"""Todo esto de hablar de filas y de columnas, crear diccionarios de listas, listas de diccionarios, es un poco confuso. Este es un buen momento para detenerse a revisar bien la estructura de datos que genera cada uno de los códigos anteriores. Es normal que si aprendieron a usar listas y diccionarios recientemente, todavía no sea muy fácil conceptualizar los tipos de datos anteriores y pensar en cuál conviene utilizar o cómo acceder a los datos que necesitan. La realidad es que hay que ganar un poco de práctica y cada vez se vuelve más simple. Luego van a poder concentrarse en el proyecto que quieren crear y no tener que pensar cada detalle de listas y diccionarios.

### Mini desafío 1.A
Leer el archivo **Tabla1.xlsx** que contiene los puntos de un campeonato. El archivo tiene cuatro columnas:
* **Equipo**
* **Puntos**
* **Goles a favor**
* **Goles en contra**

Determinar de cada equipo la diferencia de gol (goles a favor - goles en contra), y mostrar todas las diferencias usando **print**.
"""

# Ejecutar esta celda para descargar el archivo que necesitan para este desafío
 ! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Tabla1.xlsx"

import pandas as pd

archivo = pd.read_excel("Tabla1.xlsx")

data = archivo.to_dict("list") # diccionario de listas.
#La clave de los diccionarios es el nombre de la columna
#El contenido de los diccionarios es una lista con el contenido de la columna

filas = len(data["Equipo"])

print("Diferencias de gol:")

for i in range(len(data["Equipo"])):
    print(data["Equipo"][i], ":", data["Goles a favor"][i] - data["Goles en contra"][i])

"""### Mini desafío 1.B - Challenge

Determinar qué equipo es el campeón (**1ro**) y perdedor (**último**). ¿Qué columnas del archivo hay que analizar en este caso?
"""

import pandas as pd

archivo = pd.read_excel("Tabla1.xlsx", index_col = "Equipo") 
# Indicamos que la columna de indexación será Equipo.
data = archivo.to_dict("index") 
# "index" significa que vamos a obtener el contenido como diccionarios 
# donde la clave es algun campo de cada fila, en este caso la clave de los 
# diccionarios será la clave "Equipo"

# print(data)

maxpunt = 0
minpunt = 1000000
maxname = ''
minname = ''

# Vamos guardando y actualizando los "récords" mientras analizamos cada equipo
for key in data.keys():
    punt = data[key]['Puntos']
    if punt > maxpunt:
        maxpunt=punt
        maxname = key
    if punt < minpunt:
        minpunt=punt
        minname = key

print(maxname, 'resultó campeón con', maxpunt, 'puntos.' )
print(minname, 'resultó último con', minpunt, 'puntos.' )

"""### Mini desafio 1.C - Extra Challenge
Determinar qué equipos obtuvieron mas de 20 puntos, y mostrar sus diferencias de goles.

Plus: ordenar los equipos de mayor a menor en puntaje (de forma descendiente).
"""

import pandas as pd

tabla_de_puntajes = pd.read_excel("Tabla1.xlsx")

print('Todos los equipos')
for indice, equipo in tabla_de_puntajes.iterrows():
  print(equipo['Equipo'], 'obtuvo un puntaje de', equipo['Puntos'], ', y su diferencia de goles es de:', equipo['Goles a favor'] - equipo['Goles en contra'])
print()

# Nos quedamos solo con los equipos con puntaje mayor que 20
# Utilizamos la función iloc, debido a que el resultado propio de pandas nos devuelve las filas del DataFrame que cumplen con lo pedido. Nosotros queremos la 1ra, que es la única fila
equipos_top = tabla_de_puntajes[tabla_de_puntajes['Puntos'] > 20]
print("Equipos top")
for indice, equipo in equipos_top.iterrows():
  print(equipo['Equipo'], 'obtuvo un puntaje de', equipo['Puntos'], ', y su diferencia de goles es de:', equipo['Goles a favor'] - equipo['Goles en contra'])
print()

# Para el plus, tenemos que ordenar los equipos segun el puntaje que sacaron. Por defecto, se ordena de menor a mayor.
#  Como queremos de mayor a menor, le indicaremos que el ordenamiento no sea en formato
equipos_top_ordenados = equipos_top.sort_values(by=['Puntos'], ascending=False)
print("Equipos top ordenados")
for indice, equipo in equipos_top_ordenados.iterrows():
  print(equipo['Equipo'], 'obtuvo un puntaje de', equipo['Puntos'], ', y su diferencia de goles es de', equipo['Goles a favor'] - equipo['Goles en contra'])

"""## Escritura de archivos .xlsx y .csv

Es posible escribir archivos con pandas utilizando el comando [to_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html). Este método recive un *DataFrame*, por lo que si queremos escribir otro tipo de dato de python deberemos realizar una conversión con el método del mismo nombre: [DataFrame()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).

A continuación mostraremos un ejemplo que genera la siguiente estructura de datos:

|   |     Personas     | Edad |
|---|:----------------:|-----:|
| 0 |  Analía Ferreyra |   25 |
| 1 |    Martin Hugo   |   35 |
| 2 | Fernando Lorenzo |   87 |
"""

import pandas as pd

# La clave es el titulo de la columna y el contenido son listas con los items de cada columna
data = {
    "Personas" : ["Analía Ferreyra" , "Martin Hugo", "Fernando Lorenzo"],
    "Edad" : [25, 35, 87] 
}

# Con pd.DataFrame podemos generar una variable tipo DataFrame
# Recordemos que DataFrame es el tipo de dato que usa pandas
dataFrame = pd.DataFrame(data) 

print(dataFrame)

# Exportamos la información a un archivo llamado "personas.xlsx"
dataFrame.to_excel("personas.xlsx")

"""El archivo que genera el programa anterior tiene el siguiente aspecto:

<img src="https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/_assets/colab_archivos_3.png" width=400>

En Google Colab el archivo queda guardado en la pestaña *Archivos*. Si usan un entorno de desarrollo distinto el archivo será guardado en su disco de la computadora. Para ver el archivo generado pueden seguir los siguientes pasos:

<img src="https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/_assets/colab_archivos_2.png" width=400>

## Manipulación de DataFrames
"""

# Link a Youtube: https://youtu.be/K6GTx_q7AIA
# Tema: Manejo de DataFrames. 

# Dar click en el botón de play de esta celda si el video no se visualiza debajo

from IPython.display import YouTubeVideo
YouTubeVideo('K6GTx_q7AIA', width=800, height=450)

"""Además de poder convertir los datos de un archivo a una estructura de datos nativa de Python, como listas y diccionarios, Pandas tiene la posibilidad de trabajar directamente sobre un *DataFrame* usando operaciones y métodos particulares. Sería muy aburrido explicar cada uno de ellos en detalle ya que varios son muy específicos, pero podrían ser la solución perfecta para un problema muy particular. A continuación veremos las operaciones más utilizadas, confiando en que si llegan a necesitar realizar operaciones más complejas puedan encontrarlas en la [documentación de pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) o foros como StackOverflow."""

import pandas as pd

# Volvemos a abrir el archivo que fue utilizado anteriormente:
datos = pd.read_excel("Datos.xlsx") 
print(datos)

"""Usualmente necesitamos acceder a los datos dispuestos en las columnas esto se hace de forma similar a un diccionario, la forma es la siguiente:"""

# Recordar que -datos- es un DataFrame, no un diccionario.
# Pero su uso es similar:

columna = 'Quimica'
print(datos[columna])

"""Podemos ver que a diferencia de un diccionario, al mostrar una columna de la tabla usando print() aparece información adicional, como el indice de cada fila, el nombre de la columna y el tipo de dato.

Otra tarea común es acceder a una fila en particular, en el ejemplo sería acceder a un alumno en particular. Se puede lograr de la siguiente forma:
"""

indice = 0
alumno = datos.loc[indice] 
print(alumno)

"""*¿Por qué se usa .loc[indice] en vez de directamente usar corchetes?*

Normalmente se intenta que los operadores siempre signifiquen lo mismo, de forma que los corchetes deberían servir para acceder a un elemento, pero en este caso los corchetes ya se utilizan para acceder a una columna como en el ejemplo anterior, por lo cual se debe usar un operador distinto para acceder a una fila, o serían indistinguibles.

Veamos ahora cómo se puede acceder a un dato en particular del alumno:
"""

# Podemos ingresar primero a la fila y luego a la columna:

indice = 0
alumno = datos.loc[indice] 
print(alumno['Matematica'])

# Podemos ingresar primero a la columna y luego a la fila:

indice = 0
matematica = datos['Matematica']
print(matematica[indice])

"""Muchas veces les va a pasar que hay más de una forma de resolver un problema con programación, como en el ejemplo sencillo de acceder a una celda particular en una tabla.

*¿Cuál deberían usar?* Va a depender de cuál les parezca más fácil de entender, y cuál se amolde mejor a su aplicación particular. No hay una única respuesta. Por ahora alcanza con tener en cuenta que si la solución a un problema se vuelve compleja, quizá exista otra más sencilla que produzca el mismo resultado.

### Mini desafío 2.A
Calcular el promedio de las notas de química de todos los alumnos en el archivo **Datos.xlsx**.

- **Tip:** Podemos usar la función **sum**($iterable$) para obtener la suma de todos los campos. Un ejemplo de como funciona:
```python
mi_lista = [1, 2, 3, 4, 5]
total = sum(mi_lista)
print(total)
```
 ¡La función **len()** también sigue siendo válida!
"""

! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Datos.xlsx"

import pandas as pd

datos = pd.read_excel("Datos.xlsx") 
data = datos['Quimica']

print(sum(data) / len(data))

"""### Mini desafío 2.B

Escribir una funcion que reciba como parámetros: una variable de tipo **DataFrame** (la tabla de alumnos) y el índice de un alumno. Luego debe devolver con *return* el promedio de sus notas en las diferentes materias.
"""

import pandas as pd

def promedio(df, index):
    alumno = df.loc[index]
    m = alumno["Matematica"]
    f = alumno["Fisica"]
    q = alumno["Quimica"]
    return (m + f + q)/3
    
datos = pd.read_excel("Datos.xlsx")

print("El promedio del dato 0 es %0.2f " % promedio(datos, 0))
print("El promedio del dato 1 es %0.2f " % promedio(datos, 1))

"""### Otras operaciones

Veamos un ejemplo para sacar todos los promedios de los alumnos a la vez.
"""

promedios = (datos['Quimica'] + datos['Matematica'] + datos['Fisica']) / 3
print('Todos los promedios')
print(promedios)
print('El promedio maximo es', promedios.max())

"""Podemos ver que cuando se suman columnas de un *DataFrame*, se calcula la suma **elemento a elemento**, como si hiciera la operación suma para cada fila por separado. Cuando se divide por 3 la suma de las columnas, realiza la división por 3 de cada resultado por separado y queda al final 1 resultado por fila. Esto es muy práctico y también funciona con otros operadores, por lo cual se vuelve bastante intuitivo realizar cuentas sencillas. También se muestra en el ejemplo el método **.max()** que encuentra el valor máximo.

¿Cómo es que funciona esto? Para saverlo al detalle deberíamos aprender python avanzado y leer a fondo la documentación de Pandas. Sin embargo, basta con entender de que los programadores de Pandas definieron las operaciones de + (suma), - (resta), * (multiplicación), / (división), etc. para los DataFrames, permitiendo que se puedan usar de forma sencilla y eficaz.

### Filtrado

En un DataFrame es posible filtrar los datos según alguna condición. Esto se realiza de la siguiente manera:
> dataframe**[** (condición_1) **&** / **|** (condición_2) **&** / **|** (condición_3) ...  **]**

Donde dice `& / |` porque se puede elegir escribir `&` para hacer un **and**, o se puede escribir `|` para hacer un **or**. Recordar que un **and** es verdadero si se cumplen ambas condiciones, mientras que un **or** lo es si se cumple alguna de ellas. Notar también que las condiciones se escriben dentro de paréntesis.

Las condiciones siguien el siguiente formato:
> dataframe**[** propiedad **]** **>**/**<**/**<=**/**...** (número)

**Nota:** No debe ser una comparación sí o sí con un numero, se puede comparar contra cualquier cosa mientras estén definidas las comparaciones (mayor, menor, mayor o igual, igual, etc.).

Veamos un ejemplo extrayendo todos los alumnos que hayan aprobado química (nota >= 4):
"""

import pandas as pd

datos = pd.read_excel("Datos.xlsx") 
print("Datos:\n")
print(datos)

# No es necesario usar paréntesis si hay una única condición
aprobados = datos[ datos['Quimica'] >= 4 ] 
print("\nAprobados en Química:\n")
print(aprobados)

"""Podemos hacer otro ejemplo en donde mostramos los alumnos que reprobaron al menos una materia, es decir que:

(la nota de Química es menor a 4) **o** (la nota de Matemática es menor a 4) **o** (la nota de Física es menor a 4).
"""

aprobados = datos[ (datos['Quimica'] < 4) | (datos['Matematica'] < 4) | (datos['Fisica'] < 4) ]
print("Reprobaron al menos una materia:")
print(aprobados)

"""En el siguiente archivo se tienen las notas de algunos alumnos, donde la letra "A" representa que el estudiante se inscribió al examen pero estuvo Ausente y una celda vacía representa que el alumno no se inscribió al examen:"""

# Ejecutar esta celda para descargar el archivo necesario
!wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Datos2.xlsx"

import pandas as pd

datos2 = pd.read_excel("Datos2.xlsx") 
print("Datos:\n")
print(datos2)

"""Podemos ver que Pandas representa las celdas vacías con el texto "NaN" (Not a Number). Podríamos filtrar estos valores de forma similar a los ejemplos anteriores. Esta vez tendremos que usar un método específico para detectar que el valor no sea NaN:"""

datos2_matematica = datos2[ (datos2['Matematica'].notna()) & (datos2['Matematica'] != 'A')  ]

datos2_matematica = datos2_matematica['Matematica'] # Nos quedamos con la columna de interés

print('Notas válidas en Matemática: ')
print(datos2_matematica)

"""### Mini desafío 3

Obtener el promedio general sólo para aquellos alumnos que aprobaron Matemática (con nota `>= 6`) en el archivo **Datos.xlsx**.
"""

aprobadosMate = datos[(datos['Matematica']>=6)]
promedios = (aprobadosMate["Quimica"] + aprobadosMate["Matematica"] + aprobadosMate["Fisica"])/3

promedio_general = sum(promedios)/len(promedios)

print("El promedio general es %0.2f " % promedio_general)

"""# Para seguir aprendiendo

Decidimos explicar los formatos de información estructurada más utilizados, pero como se pueden imaginar, existen muchos más formatos que se utilizan para diferentes tareas.

Como contenido extra, sólo para aquellos interesados en seguir investigando, incluímos dos Anexos al final de la clase relacionados con el formato *JSON*.

La lectura de los Anexos es **100% opcional** y NO es un requisito para continuar con el curso.

# Ejercitación integradora $\newcommand{\dif}{\bigstar}$$\newcommand{\facil}{\color{\green}{\dif}}$ $\newcommand{\pieceofcake}{\color{\cyan}{\dif}}$$\newcommand{\medio}{\color{\yellow}{\dif\dif}}$$\newcommand{\media}{\medio}$$\newcommand{\normal}{\medio}$  $\newcommand{\dificil}{\color{\orange}{\dif\dif\dif}}$ $\newcommand{\imposible}{\color{\red}{\dif\dif\dif\dif}}$

## $\facil$ Copy
Temas:
*   **Uso de librerías**
*   **Manejo de archivos**

Armar una función que copie un archivo *.xlsx*, y lo guarde como "Copia 1 - $nombre$", de ya existir debe guardarlo como Copia 2 -, Copia 3 - , ...

Usar la libreria **os** para chequear si existe el archivo. Tips:

- os.path.exists($nombre$) devolverá True si ya existe

- Se puede importar con: `import os`
"""

import os
import shutil

def func(nombre):
    repeticion = 1

    while os.path.exists("Copia " + str(repeticion) + " "+ nombre):
        repeticion += 1
        
    shutil.copyfile(nombre, "Copia " + str(repeticion) + " "+ nombre)
    
        
func('Tabla1.xlsx')

"""## $\facil$ California Housing

Temas:
*   ***Analísis de información estructurada***
*   ***Librerías***
"""

# Descargar el archivo california_housing_train.xlsx.
! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/california_housing_train.xlsx"

"""Este archivo contiene un conjunto de datos de viviendas de California, el cual fue extraido del censo de nacional estadounidense de 1990. Para mas info sobre el set de datos: https://developers.google.com/machine-learning/crash-course/california-housing-data-description

Extraer la siguiente información:

*   ¿Cuantas casas hay con valor 'median_house_value' mayor a 80000 tomando de la longitud -120  a -118? Rta: 5466
*   ¿Cual es el promedio de habitaciones por manzana ('total_rooms') de estas casas? Rta: 2466.31

*   ¿Cual es la casa más cara? ¿Cuántas hay con este valor? Rta: 500001.0 - 814 

*   $\medio$ Obtener la media y la varianza de la propiedad 'median_house_value'. Rta: 207300.91 - 13451442293.57

**Tip:** ¡Pueden investigar funciones de numpy para conseguir la media y la varianza!  [numpy.var](https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.var.html)
"""

import pandas as pd
import numpy as np

archivo = pd.read_excel("california_housing_train.xlsx") 

#Pregunta 1 y 2 (utilizando filtrado)
ans = 0
hab = 0
filtro_lon = (-120 <= archivo['longitude']) & (archivo['longitude'] <= -118)
filtro_val = archivo['median_house_value'] > 80000
ans = len( archivo[filtro_lon & filtro_val] )
hab = sum(archivo[filtro_lon & filtro_val]['total_rooms'])
print(ans)
print(hab/ans)

#Pregunta 1 y 2 (sin utilizar filtrado)
ans = 0
hab = 0
for i,lon in enumerate(archivo['longitude']):
    if -120 <= lon and lon<=-118 :
        if archivo['median_house_value'][i] > 80000:
            ans+=1
            hab+=archivo['total_rooms'][i]
print(ans)
print(hab/ans)

#Pregunta 3
m = max(archivo['median_house_value'])
c = sum(archivo['median_house_value'] == m)
print(m)
print(c)

#pregunta 4
m = np.mean(archivo['median_house_value'])
v = np.var(archivo['median_house_value'])
print(m)
print(v)

"""## $\medio$ Llévame en tu bicicleta

Temas:
*   ***Analisís de información estructurada***
*   ***Librerías***

El gobierno de la Ciudad de Buenos Aires recolecta datos acerca del uso de los servicios de bicicletas públicas (ecobici) y publica [parte de ello](https://data.buenosaires.gob.ar/dataset/bicicletas-publicas)[s](https://www.youtube.com/watch?v=-UV0QGLmYys&ab_channel=CarlosVivesVEVO).


Para este ejemplo usaremos los primeros 10000 viajes de la base de datos del 2021. Están invitados a analizar todos los viajes, pero para ello les recomendamos descargar el archivo y ejecutar su programa en forma local (no en Google Golab).

Se quiere conocer más acerca del uso que le dan los usuarios al sistema, por lo cual su tarea será extraer la siguiente información:

* ¿Qué porcentaje de los viajes se completaron en estado NORMAL?
* ¿Cuál es la duración promedio de cada viaje? (Los datos están en segundos)
* ¿A qué hora del día se realizaron más viajes? (por ejemplo: de 16hs a 17hs)
* ¿Cuántas estaciones diferentes fueron utilizadas?
* Para cada estación utilizada como inicio de un viaje, imprimirlas ordenadas por cantidad de viajes que iniciaron de la misma.

**Tip:** Recuerden investigar los métodos que tienen los DataFrames para ver si alguno de ellos les ayuda a resolver un problema particular.

"""

# Una vez descargado el archivo se llamará "recorridos-realizados-2021-sample.csv"
! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/recorridos-realizados-2021-sample.csv"

import pandas as pd
import numpy as np

archivo = pd.read_csv("recorridos-realizados-2021-sample.csv")

# Obtenemos el número de filas en el archivo
numero_de_filas = len(archivo)

# Usamos .value_counts() para obtener una cuenta de cuantas veces ocurre cada valor
# Dividimos la cantidad de veces que aparece 'NORMAL' por la cantidad de filas
estado_count = archivo['Estado cerrado'].value_counts()
porcentaje_normal = 100*(estado_count['NORMAL'] / numero_de_filas)
print(f'El {porcentaje_normal:.2f}% de los viajes se completaron en estado NORMAL')

# Usamos .mean() para calcular el promedio
duracion_promedio = round(archivo['Duración'].mean())
print(f'La duración promedio es de {duracion_promedio//60} minutos {duracion_promedio%60} segundos')

# Con pd.to_datetime() convertimos strings a objetos datetime
# Usamos .dt.hour para obtener únicamente el valor de hora
# Con .value_counts() y luego .idxmax() encontramos el índice que más veces aparece
horarios_de_inicio = archivo['Fecha de inicio']
horarios_de_inicio = pd.to_datetime(horarios_de_inicio)
horas_de_inicio = horarios_de_inicio.dt.hour
hora_pico = horas_de_inicio.value_counts().idxmax()
print(f'La hora más concurrida es de {hora_pico}hs a {hora_pico+1}hs')

# Con pd.concat unimos las columnas de estaciones de inicio y fin,
# en caso de que una estación aparece sólo en una de ellas
# Usando len() y .value_counts() encontramos la cantidad total de estaciones
estaciones_inicio = archivo['Nombre de estación de inicio']
estaciones_fin = archivo['Nombre de estación de fin de viaje']
estaciones_total = pd.concat([estaciones_inicio, estaciones_fin])
print(f'Se utilizaron {len(estaciones_total.value_counts())} estaciones en total')

"""## $\medio$ El tiempo es dinero

Temas:
*   ***Analisís de información estructurada***
*   ***Librerías***

La administración del dinero es una tarea que requiere una altísima fiabilidad. 
En esta ocasión tu objetivo será programar un script que **actualize la cantidad** de dinero de una serie de usuarios a partir de la información de las transferencias que fueron realizadas. 
Más concretamente recibiras una **base de datos con la cantidad de dinero de una serie de usuarios**, un base de datos con una serie de transferencias que los usuarios se realizan entre si, y deberás generar con eso **una nueva base de datos con el dinero actualizado de cada usuario**.

*   Importar el archivo **Finanzas.xlsx** que contiene la cantidad de dinero de los usuarios y las transferencias en dos hojas de archivo.
*   Exportar un archivo **usuarios_actualizados.xlsx** que contiene las cantidades de dinero actualizadas.

<img src="https://psmag.com/.image/t_share/MTI3NTgyMzg2MzE2NzAxNjY2/time-is-money.jpg" width=400>


"""

! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/Finanzas.xlsx"

"""Debes procesar las transferencias y actualizar el saldo de cada usuario (crear un nuevo archivo excel con los saldos actualizados)."""

#leemos los usuarios en el formato index, para tenerlos indexados por el nombre de usuario
#Es decir, para que la clave sea el nombre de los usuarios y sea facil referenciar
#a los usuarios
usuarios_archivo = pd.read_excel("Finanzas.xlsx", "Usuarios",index_col="Usuario") 

#Mostramos los usuarios recien leidos
print("Usuarios:")
print(usuarios_archivo)
print(" ")

usuarios = usuarios_archivo.to_dict("index")


#Leemos las transferencias en el formato records, es decir conseguimos una lista con las transferencias
transferencias_archivo = pd.read_excel("Finanzas.xlsx", "Transferencias")
transferencias = transferencias_archivo.to_dict("records")

#Mostramos las transferencias recien realizadas
print("Transferencias:")
print(transferencias_archivo)
print(" ")

for transferencia in transferencias: # iteramos todas las transferncias distintas
    # obtenemos la info de la transferencia
    emisor = transferencia["Emisor"]
    receptor = transferencia["Receptor"]
    monto = transferencia["Monto"]

    usuarios[emisor]["Presupuesto"] -= monto # le retiramos el dinero al emisor
    usuarios[receptor]["Presupuesto"] += monto #le ortorgamos el dinero al receptor

# generamos el nuevo archivo excel, orient="index" provoca que las claves se coloquen en la primera fila,
# En este caso los usuarios son las claves y queremos que la primerea fila del archivo
# tenga todos los nombres de usuario
usuarios_actualizados = pd.DataFrame.from_dict(usuarios, orient="index")

#Mostramos los saldos de los usuarios luego de realizar las transferencias
print("Usuarios luego de realizar las transferencias:")
print(usuarios_actualizados)

#Grabamos la información final
usuarios_actualizados.to_excel("usuarios_actualizados.xlsx")

"""## $\dificil $ Buscando la $


Tema:
*   ***Procesamiento de información estructurada***
*   ***Librerías***

Utilizando el set de datos del archivo **california_housing_train.xlsx**

Dividir el area cubierta por el censo en cuadrantes de 0.5 de latitud x 0.5  de longitud, encontrar para qué cuadrante el valor medio de 'median_house_value' es máximo. Asignar el paso como una variable para que pueda cambiarse facilmente. Para filtrar las zonas de muy baja residencia descarten los valores cuando hay menos de 100 casas.

Datos utiles:
- Minimo de longitud: -124.3
- Máximo de longitud: -114.3
- Minimo de latitud: 32.5
- Máximo de latitud: 42.5

**Tips:** El programa va a tardar en correr, no se asusten! Pueden investigar funciones de numpy para ayudarlos a resolver el problema, como [numpy.arange](https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html).

**Nota final**: ¡Busquen en el mapa estas coordenadas para ver donde quedan! 




"""

import pandas as pd
import numpy as np

archivo = pd.read_excel("california_housing_train.xlsx") 
paso = .5

lats = np.arange(32.5,42.5,paso)
lons = np.arange(-124.3,113.3,paso) 
maximoValor = 0
maximaLat = 0
maximaLon = 0
for lat in lats:
    for lon in lons:
        data = archivo[(archivo['latitude']>=lat) & (archivo['latitude']<=lat+paso)]
        data = data[(data['longitude']>=lon) & (data['longitude']<=lon+paso)]
        if(len(data)>100):
            m = np.mean(data['median_house_value'])
            if m > maximoValor:
                maximaLat = lat
                maximaLon = lon
                maximoValor = m
                
print('Latitude:',maximaLat,'Longitude',maximaLon,'Price',maximoValor)

"""## $\imposible $ Unificación de bases de datos

El objetivo de este problema es unificar dos bases de datos que contienen mails. Esto quiere decir, tomar dos bases de datos de formato *.csv*: **lista1.csv** y **lista2.csv** y combinarlas en una misma base de datos **listafinal.csv**. 
El contenido de las bases de datos son listas de mails, que contienen mails y otras informaciones de distintos usuarios. Tener en cuenta que las dos bases de datos pueden tener informaciones distintas de los usuarios.

**Recomendamos** descargar los archivos para ver su contenido (Con excel pueden abrirlos, pensar que un csv es prácticamente equivalente a un excel).

"""

! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/lista1.csv" 
# primera lista de clientes

! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/lista2.csv"
# segunda lista de clientes

! wget "https://raw.githubusercontent.com/IEEESBITBA/Curso-Python/master/Curso_Analisis_de_Datos_Datos/lista_final.csv"
# ejemplo de como tiene que quedar (las columnas pueden quedar en otro orden! salvo la primera)

import pandas as pd

# aca almacenamos las bases de datos que vamos a unificar
listas = [ "lista1.csv", "lista2.csv" ]

# en este diccionario vamos a ir amlacenando la información de la base de datos unificada
# la clave son los mails, el contenido la información de los usuarios

clientes = dict() 

#en este set almacenamos todas las columnas que se van progresivamente encontrando
todosloscampos = set() #set=conjunto


for lista in listas: # iteramos todas las bases de datos 

    # leemos el contenido indexando por mail (es decir la clave de los diccionarios será el mail de los usuarios)
    archivo = pd.read_csv(lista, index_col =["Mail"])
    data = archivo.to_dict("index") 
    
    # mostramos en pantalla
    print("Base de datos", lista)
    print(archivo)

    # iteramos los mails de la base de datos
    for mail in data: 
        # si el mail es uno nuevo para nuetra base de datos unificada, lo inicializamos como un diccionario vacio sin información
        # la cual se la agregaremos despues
        # si el mail ya existe no es necesario, significa que lo vimos en una base de datos anterior

        if mail not in clientes: 
            clientes[mail] = dict() 
        
        # leemos todos los campos (las columnas) que tenemos del mail en la base de datos original que estamos procesando
        campos = data[mail]

        # iteramos todos los campos del mail encontrado, y le asignamos sus valores en la base de datos unificada
        for campo in campos:
            # le asignamos a "clientes" que es la base de datos unificada el campo actual
            # que esta en data[mail], que tiene la información de la base de datos que estamos procesando del
            # campo correspondiente 
            clientes[mail][campo] = data[mail][campo]

            # le agregamos al set de campos (columas) el campo encontrado
            # como es un set los repetidos no van a agregarse
            todosloscampos.add(campo)

    print("  ")
            
# Por ultimo escribimos el archivo final, colocando las claves de los elementos de la base unificada (es decir los mails)
# En la primera columna (por eso orient="index")

df = pd.DataFrame.from_dict(clientes, orient='index')

# Mostramos los resultados y los guardamos en un archivo final
print("Base de datos unificada")
print(df)

df.to_csv('listafinal.csv')

"""# Anexos

## Anexo A: JSON
La lectura de los Anexos es **100% opcional** y NO es un requisito para continuar con el curso.

*JSON* es un formato de representación de información estructurada que es de gran utilidad. Su sintaxis es simple y fácil de leer a simple vista, además de que tiene una gran similitud con la sintaxis propia de Python. En la [página web](https://www.json.org/json-es.html) de *JSON* hay explicaciones bastante claras acerca de los detalles de su sintaxis.

En *JSON* los objetos se rodean con llaves `{objeto}`, las listas con corchetes `[lista]` y los strings con comillas dobles `"string"`. Por el momento se puede pensar que un objeto es igual a un diccionario de Python, pudiendo almacenar datos con claves, por ejemplo:

```json
{  
  "columna_1": [1, 8, 4, 6, 2, 8, 5],
  "columna_2": [99, 56, 223, 301, 56, 2],
  "columna_2": [0, -1, -66, -210, -333, 334]
}
```

El texto de arriba es código de Python _válido_ y un objeto json! Si quisieramos cargarlo a nuestro código Python bastaría con copiarlo y pegarlo a nuestro código. Pero no siempre vamos a estar nosotros para copiar y pegar el texto json. 

En el caso presentado a continuación se tiene un string de código json y precisamos [leerlo y procesarlo](https://www.w3schools.com/python/python_json.asp). Para eso usamos el modulo `json` de Python. A continuación se muestra un ejemplo:
"""

import json
s = '{ "a" : [1, 2, 3], "b" : [4, 6, 8], "c":[99, 98, 97] }'
d= json.loads(s)
print(d["a"])
print(len(d["b"]))
print(sum(d["c"]))

"""Verán que se imprimen la lista `"a"`, la longitud de la lista `"b"` y la suma de los elementos de la lista `"c"`.

Vamos a utilizar en el próximo desafío **opcional** la librería `json` para leer el texto que nos llega por `input()`, lo cual podría ocurrir si estamos comunicándonos con un servidor.

### **Opcional**: Mini-desafío json
Estás encargado de un servidor con millones de usuarios. 

Se pide escribir un programa que reciba el email y contraseña del usuario y se fije si existe el usuario y si coincide la contraseña.

Se tienen datos encolumnados en formato json que nos llegan del siguiente formato:
```json
{
	"usuarios": ["mica@mail.co", "jerry@gma.com","alber@soup.co"],
	"contra": ["abc123","caballitos","yoloswag"]
}
```
La entrada del programa son tres lineas, el programa entonces va tener tres `input()`. La primer linea contiene el `json`, la segunda el `email` a verificar, y la tercera la `contraseña`. Por ende, las primeras lineas de su programa podrían ser:
```python
import json
usuarios = json.loads(input())
email = input()
password = input()
```

La salida del programa será `OK` si el usuario **se encuentra en la base de datos** ***y*** **si coincide la contraseña**, imprimimos `DNE` (does not exist) si el usuario no existe y `NO` en cualquier otro caso.

#### Caso ejemplo
**Entrada**:
```plaintext
{"usuarios": ["mica@mail.co","jerry@gma.com","alber@soup.co"],"contra": ["abc123","caballitos","yoloswag"]}
mica@mail.co
caballitos
```
El usuario existe y la contraseña también... pero no le corresponde la contraseña `caballitos` al usuario `mica@mail.co` (la contraseña de `mica@mail.co` sería `abc123`) por ende imprimimos:

**Salida**
```
NO
```

_Considere que no hay usuarios repetidos_.
"""

import json
usuarios = json.loads(input())
email = input("Mail:")
password = input("Contraseña")

if email in usuarios["usuarios"]:
  index = usuarios["usuarios"].index(email)
  if password == usuarios["contra"][index]:
    print("OK")
  else:
    print("NO")

else:
  print("DNE")

"""## Anexo B: API's
La lectura de los Anexos es **100% opcional** y NO es un requisito para continuar con el curso.

En este curso, uno de los objetivos es poder automatizar tareas comunes. Ya empezamos a ver como podemos interactuar con archivos de datos desde nuestro programa en Python, pero esto puede no ser suficiente. 

Es usual tener que interactuar con una aplicación, por ejemplo, podríamos querer acceder a una página web, o al servidor de nuestra empresa. Para lograr la interacción entre una aplicación y nuestro programa se utilizan API's (Application Programming Interface) las cuales permiten estandarizar el formato de la información que se intercambia. 

Para lograr esta comunicación una de las herramientas más comunes es el uso de archivos *JSON* ya que de manera simple y concisa pueden representar estructuras de datos relativamente complejas. 

No todas las aplicaciones tendrán API's. Además, no todas las API's proveen el acceso a todos los datos deseados, por lo cual es posible que haya que recurrir a otros métodos menos elegantes para obtener la información deseada, tales como los **scrapers**.

[Este video](https://youtu.be/BxV14h0kFs0) hecho por Tom Scott puede ayudar para comprender un poco más acerca de qué se tratan las API's.

Para mostrar un ejemplo práctico del uso de API's, utilizamos uno de los códigos de ejemplo en la documentación de la API de YouTube que pueden ver en [este link](https://developers.google.com/youtube/reporting/v1/code_samples/python?hl=es#retrieve_daily_channel_statistics). Las aplicaciones de Google (Maps, Youtube, etc.) suelen tener API's relativamente buenas y completas. En este caso el ejemplo obtiene ciertas estadísticas del [Canal de YouTube de IEEE-ITBA](https://www.youtube.com/channel/UCpWHvOSiPtDIwIw8Tb_9g6A/featured) entre los días 1 y 13 del mes de octubre 2020. Los resultados **reales** de este programa se muestran a continuación tal cual como fueron enviados por la API de YouTube y recibidos por nuestro programa en Python:

```json
{
    "columnHeaders": [
        {
            "columnType": "DIMENSION",
            "dataType": "STRING",
            "name": "day"
        },
        {
            "columnType": "METRIC",
            "dataType": "INTEGER",
            "name": "estimatedMinutesWatched"
        },
        {
            "columnType": "METRIC",
            "dataType": "INTEGER",
            "name": "views"
        },
        {
            "columnType": "METRIC",
            "dataType": "INTEGER",
            "name": "likes"
        },
        {
            "columnType": "METRIC",
            "dataType": "INTEGER",
            "name": "subscribersGained"
        }
    ],
    "kind": "youtubeAnalytics#resultTable",
    "rows": [
        [
            "2020-10-01",
            26,
            19,
            0,
            0
        ],
        [
            "2020-10-02",
            2,
            14,
            0,
            0
        ],
        [
            "2020-10-03",
            120,
            78,
            0,
            1
        ],
        [
            "2020-10-04",
            3280,
            1203,
            75,
            88
        ],
        [
            "2020-10-05",
            2064,
            747,
            22,
            44
        ],
        [
            "2020-10-06",
            2290,
            824,
            28,
            26
        ],
        [
            "2020-10-07",
            2817,
            950,
            13,
            20
        ],
        [
            "2020-10-08",
            4594,
            1491,
            9,
            14
        ],
        [
            "2020-10-09",
            4238,
            1254,
            17,
            19
        ],
        [
            "2020-10-10",
            31783,
            3231,
            126,
            102
        ],
        [
            "2020-10-11",
            6233,
            1529,
            18,
            22
        ],
        [
            "2020-10-12",
            4786,
            1138,
            9,
            7
        ],
        [
            "2020-10-13",
            3977,
            761,
            17,
            13
        ]
    ]
}
```

Como se puede observar, el formato de los datos está definido por la API de YouTube, y consiste de una lista ```columnHeaders``` con los datos de cada columna, como por ejemplo el nombre de la columna, y luego una lista ```rows``` con los datos de cada fila en el mismo orden en que se indicaron las columnas.

Usando la API de YouTube, se puede automatizar el análisis de las estadísticas de videos e incluso realizar cambios acordemente para mejorar su rendimiento, como por ejemplo, cambiar el título o la imagen de portada. 

Otro ejemplo podría ser el uso de la API de Google Maps para incorporar funcionalidad de mapas o de geolocalización a nuestra aplicación. En conclusión, las API's nos permiten interactuar desde nuestro programa con otras aplicaciones de forma simple y estandarizada para aprovechar todas las herramientas que nos ofrecen, y automatizar este proceso utilizando un lenguage de programación como Python.
"""